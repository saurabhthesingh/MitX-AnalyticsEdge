---
title: "Boston Housing Data"
author: "Saurabh"
date: "5/19/2020"
output: html_document
---

## Data 

Each entry corresponds to a census *tract, a statistical
division of the area that is used by researchers to
break down towns and cities.
• There will usually be multiple census tracts per town.
• LON and LAT are the longitude and latitude of the
center of the census tract.
• MEDV is the median value of owner-occupied
homes, in thousands of dollars.
CRIM is the per capita crime rate
• ZN is related to how much of the land is zoned for
large residential properties
• INDUS is proportion of area used for industry
• CHAS is 1 if the census tract is next to the Charles
River
• NOX is the concentration of nitrous oxides in the air
• RM is the average number of rooms per dwelling
AGE is the proportion of owner-occupied units built
before 1940
• DIS is a measure of how far the tract is from centers
of employment in Boston
• RAD is a measure of closeness to important
highways
• TAX is the property tax rate per $10,000 of value
• PTRATIO is the pupil-teacher ratio by town


## Load Libraries
```{r}
library(tidyverse) 
library(rpart)        #CART 
library(rpart.plot)   #CART
library(caTools)      #Split
library(caret)        #Cross Validation
library(e1071)        #Cross Validation
```


## Load Data
```{r}
boston <- read.csv("boston.csv")
str(boston)
```

## Plot Observations

We're interested to see how prices vary by location.
So firts lets see how points are laid out.
```{r}
plot(boston$LON,boston$LAT)

points(boston$LON[boston$CHAS==1],boston$LAT[boston$CHAS==1], col= "blue" , pch = 19)
points(boston$LON[boston$NOX >= 0.55],boston$LAT[boston$NOX >= 0.55], col= "red" , pch = 19) 

```
Dense Central area is city.


Air Pollution
```{r}
summary(boston$NOX)
```

```{r}
summary(boston$MEDV)
```

```{r}
plot(boston$LON,boston$LAT)
points(boston$LON[boston$MEDV >= 21.20],boston$LAT[boston$MEDV >= 21.20], col= "red" , pch = 19)
```

## Linear Reg using LAT & LON
```{r}
plot(boston$LAT , boston$MEDV)
plot(boston$LON , boston$MEDV)
latlonlm = lm(MEDV ~ LAT + LON , data= boston)
summary(latlonlm)
```

## Visualize Regression
```{r}

plot(boston$LON,boston$LAT)
points(boston$LON[boston$MEDV >= 21.20],boston$LAT[boston$MEDV >= 21.20], col= "red" , pch = 19)


latlonlm$fitted.values
points(boston$LON[latlonlm$fitted.values >= 21.20],boston$LAT[latlonlm$fitted.values >= 21.20], col= "blue" , pch = "$")

```

We can see that lm isn't doing rather good.
Let's see how regression tress perform .


## CART model
```{r}
latlontree = rpart(MEDV ~ LAT + LON , data = boston )
prp(latlontree)
```


## Visualize o/p

```{r}
plot(boston$LON,boston$LAT)
points(boston$LON[boston$MEDV >= 21.20],boston$LAT[boston$MEDV >= 21.20], col= "red" , pch = 19)


fittedvalues = predict(latlontree)
points(boston$LON[fittedvalues >= 21.20],boston$LAT[fittedvalues >= 21.20], col= "blue" , pch = "$")
```

It does a slightly better job than the linear model.

##Simplify tree by inc minbucket
```{r}
latlontree = rpart(MEDV ~ LAT + LON , data= boston , minbucket = 50)
plot(latlontree)
text(latlontree)
```

## Visualize O/p
```{r}
plot(boston$LON,boston$LAT)
abline(v= - 71.07)
abline(h = 42.21)
abline(h = 42.17)
points(boston$LON[boston$MEDV>=21.2], boston$LAT[boston$MEDV>=21.2], col="red", pch=20)

```


## Using all Variables

```{r}
set.seed(123)
split = sample.split(boston$MEDV , SplitRatio = 0.7)
train = subset(boston, split == TRUE )
test = subset(boston , split == FALSE)
```


### Linear reg
```{r}
linreg = lm(MEDV ~ LAT + LON + CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO, data=train)
summary(linreg)
```

### Make Predi
```{r}
linreg.pred = predict(linreg , newdata = test)
linreg.sse = sum((linreg.pred - test$MEDV)^2)
linreg.sse
```

## Cart Model
```{r}
tree = rpart(MEDV ~ LAT + LON + CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO, data=train)
prp(tree)
```

## Predictions
```{r}
tree.pred = predict(tree, newdata = test)
tree.sse = sum((tree.pred - test$MEDV)^2)
tree.sse
```

## Cross Validation 

```{r}
tr.control = trainControl(method = "cv" , number = 10)
cp.grid = expand.grid(.cp = (0:10)* 0.001)
```


```{r}
tr = train(MEDV ~ LAT + LON + CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO,
           data = train, method = "rpart", trControl = tr.control, tuneGrid = cp.grid)

tr
```

Extract Tree :
```{r}
best.tree = tr$finalModel
prp(best.tree)
```

## Make pred
```{r}
best.tree.pred = predict(best.tree , newdata = test)
best.tree.sse = sum((best.tree.pred - test$MEDV)^2)
best.tree.sse
```

```{r}
linreg.sse
```


Cross Validation improved performance of tree model , 
but Linear Reg Model was better overall.